\section{Grundlagen}\sectionFrame

\begin{frame}{Grundlagen: Virtual Reality \& monokulare Rekonstruktion}
    \textbf{VR-Hardware heute:}
    \begin{itemize}
        \item HMDs wie Meta Quest 3 mit integrierten RGB-Kameras
        \item Kein Tiefensensor $\Rightarrow$ klassische RGB-D-Verfahren nicht einsetzbar
    \end{itemize}
    
    \vspace{0.8em}
    \textbf{RTReconstruct-Ziel:}
    \begin{itemize}
        \item Tiefe aus Bildsequenzen rekonstruieren (SLAM, volumetrische Verfahren)
        \item Ergebnisse in laufende VR-Anwendung streamen
        \item Mehrere Rekonstruktionsmodelle parallel austauschbar
    \end{itemize}
\end{frame}

\begin{frame}{Grundlagen: 3D-Rekonstruktion}
    \textbf{Der Prozess:}
    \begin{itemize}
        \item 2D-Bilder $\rightarrow$ 3D-Geometrie
        \item Tiefe aus Kamerabewegung + Bildsequenzen (monokulare Rekonstruktion)
    \end{itemize}
    
    \vspace{0.8em}
    \textbf{Zentrale Unterscheidung nach Pose-Anforderung:}
    \begin{itemize}
        \item \textbf{Externe Posen} (z.\,B. NeuralRecon, VisFusion): System liefert Kameraposen
        \item \textbf{Interne Pose-Schätzung} (z.\,B. MASt3R-SLAM, SLAM3R): Modell schätzt Posen selbst
    \end{itemize}
    
    \vspace{0.8em}
    \textbf{Implikation für RTReconstruct:}
    \begin{itemize}
        \item Diese Heterogenität erfordert flexible System-Architektur
        \item Beide Kategorien müssen über einheitliche Schnittstelle integrierbar sein
    \end{itemize}
\end{frame}

\begin{frame}{Grundlagen: 3D-Repräsentationsformate}
    \begin{columns}[T]
        \column{0.5\textwidth}
        \textbf{Punktwolken}
        \begin{itemize}
            \item Ungeordnete 3D-Punkte
            \item Speichereffizient
            \item Schnelle Visualisierung
        \end{itemize}
        
        \column{0.5\textwidth}
        \textbf{Meshes}
        \begin{itemize}
            \item Explizite Oberflächengeometrie
            \item GLB-Format (binär, kompakt)
            \item Besser für Kollisionen
        \end{itemize}
    \end{columns}
    \vfill
    \begin{tcolorbox}[box5, boxsep=0.5em]
        \centering
        \textbf{RTReconstruct muss beide Formate handhaben!} 
    \end{tcolorbox}
\end{frame}

\begin{frame}{Grundlagen: Zielumgebung Va.Si.Li-Lab}
    \textbf{Multi-User VR-Plattform:}
    \begin{itemize}
        \item Basis-Technologie: Unity + Ubiq-Framework
        \item Designed für kollaborative, simulationsbasierte Lernszenarien
        \item Bereits vorhanden: Tracking, Netzwerk-Sync, Szenenlogik
    \end{itemize}
    
    \vspace{0.8em}
    \textbf{RTReconstruct als Modul:}
    \begin{itemize}
        \item Nutzt bestehendes Tracking-System für Kameradaten
        \item Erhält Rekonstruktionsergebnisse vom Backend
        \item Visualisiert Ergebnisse im gemeinsamen 3D-Raum
    \end{itemize}
\end{frame}